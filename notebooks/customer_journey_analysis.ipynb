{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9e8279",
   "metadata": {},
   "source": [
    "# Customer Journey Analysis\n",
    "# This notebook analyzes customer journeys across different products, visualizing patterns in purchasing behavior, demographics, and product adoption sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e994e0",
   "metadata": {},
   "source": [
    "## Import and plot-style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cfcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use(\"seaborn-v0_8-dark-palette\")\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abcd216",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll load all ABT_score files and combine them with appropriate target labels.\n",
    "def load_abt_files():\n",
    "    \"\"\"Load all ABT_score files and combine them with appropriate target labels\"\"\"\n",
    "    abt_files = list(Path('../data').glob('ABT_[Ss]core_*.csv'))\n",
    "    \n",
    "    if not abt_files:\n",
    "        print(\"No ABT_score_*.csv files found in current directory!\")\n",
    "        print(\"\\nCurrent directory contents:\")\n",
    "        print([f.name for f in Path('../data').glob('*')])\n",
    "        print(\"\\nPlease ensure your ABT_score_*.csv files are in the data directory.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(abt_files)} ABT_score files:\")\n",
    "    for f in abt_files:\n",
    "        print(f\"  - {f.name}\")\n",
    "    \n",
    "    dfs = []\n",
    "    for file_path in abt_files:\n",
    "        product = file_path.stem.split('_')[-1]\n",
    "        try:\n",
    "            print(f\"\\nLoading {product} data...\")\n",
    "            df = pd.read_csv(file_path, sep=';')\n",
    "            print(f\"Successfully loaded {len(df)} rows for {product}\")\n",
    "            df['product_type'] = product\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path.name}: {str(e)}\")\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Load the data\n",
    "combined_df = load_abt_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a55e99",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Clean and preprocess the combined dataset\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    date_columns = [col for col in df.columns if 'Date' in col or 'date' in col or \n",
    "                   col.startswith(('mFirst_', 'mLast_'))]\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    \n",
    "    # Fill numeric NaNs with 0\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(0)\n",
    "    \n",
    "    # Convert binary columns to int\n",
    "    binary_columns = [col for col in df.columns if col.startswith(('Have_', 'Had_', 'Optout_'))]\n",
    "    for col in binary_columns:\n",
    "        df[col] = df[col].fillna(0).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "combined_df = preprocess_data(combined_df)\n",
    "\n",
    "# Display sample of preprocessed data\n",
    "print(\"Sample of preprocessed data:\")\n",
    "display(combined_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08cec7a",
   "metadata": {},
   "source": [
    "## Customer Journey Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the sequence of products purchased by customers.\n",
    "def analyze_product_sequence(df):\n",
    "    \"\"\"Analyze the sequence of products purchased by customers with enhanced timeline analysis\"\"\"\n",
    "    product_cols = [col for col in df.columns if col.startswith('mFirst_')]\n",
    "    \n",
    "    timeline_data = []\n",
    "    customer_journeys = {}\n",
    "    \n",
    "    for customer_id in df['sCustomerNaturalKey'].unique():\n",
    "        customer_data = df[df['sCustomerNaturalKey'] == customer_id]\n",
    "        \n",
    "        # Get product acquisition dates\n",
    "        products = []\n",
    "        for col in product_cols:\n",
    "            product = col.replace('mFirst_', '')\n",
    "            date = customer_data[col].iloc[0]\n",
    "            if pd.notna(date):\n",
    "                products.append({\n",
    "                    'sCustomerNaturalKey': customer_id,\n",
    "                    'product': product,\n",
    "                    'acquisition_date': date\n",
    "                })\n",
    "        \n",
    "        # Sort products by date\n",
    "        products = sorted(products, key=lambda x: x['acquisition_date'])\n",
    "        timeline_data.extend(products)\n",
    "        \n",
    "        # Create journey sequence\n",
    "        if products:\n",
    "            journey = ' → '.join([p['product'] for p in products])\n",
    "            customer_journeys[customer_id] = {\n",
    "                'sequence': journey,\n",
    "                'length': len(products),\n",
    "                'duration_days': (products[-1]['acquisition_date'] - products[0]['acquisition_date']).days,\n",
    "                'first_product': products[0]['product'],\n",
    "                'last_product': products[-1]['product']\n",
    "            }\n",
    "    \n",
    "    return pd.DataFrame(timeline_data), pd.DataFrame.from_dict(customer_journeys, orient='index')\n",
    "\n",
    "# Analyze product sequences\n",
    "timeline_df, journey_df = analyze_product_sequence(combined_df)\n",
    "\n",
    "# Display summary of product sequences\n",
    "print(\"Most common first products:\")\n",
    "display(product_timeline.groupby('sCustomerNaturalKey')\n",
    "        .first()['product']\n",
    "        .value_counts()\n",
    "        .head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e9309",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Journey Sankey Diagram\n",
    "def plot_customer_journey_sankey(journey_df, max_paths=10):\n",
    "    \"\"\"Create an improved Sankey diagram showing actual journey flows\"\"\"\n",
    "    # Get most common sequences\n",
    "    sequence_counts = journey_df['sequence'].value_counts().head(max_paths)\n",
    "    \n",
    "    # Create nodes and links\n",
    "    nodes = set()\n",
    "    links = []\n",
    "    \n",
    "    for sequence, count in sequence_counts.items():\n",
    "        products = sequence.split(' → ')\n",
    "        \n",
    "        # Add all products to nodes\n",
    "        nodes.update(products)\n",
    "        \n",
    "        # Create links between consecutive products\n",
    "        for i in range(len(products) - 1):\n",
    "            links.append({\n",
    "                'source': products[i],\n",
    "                'target': products[i + 1],\n",
    "                'value': count\n",
    "            })\n",
    "    \n",
    "    # Convert nodes to list and create node indices\n",
    "    nodes = list(nodes)\n",
    "    node_indices = {node: i for i, node in enumerate(nodes)}\n",
    "    \n",
    "    # Create Sankey diagram\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node=dict(\n",
    "            pad=15,\n",
    "            thickness=20,\n",
    "            line=dict(color=\"black\", width=0.5),\n",
    "            label=nodes,\n",
    "            color=\"lightblue\"\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=[node_indices[link['source']] for link in links],\n",
    "            target=[node_indices[link['target']] for link in links],\n",
    "            value=[link['value'] for link in links]\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text=\"Top Customer Journey Paths\",\n",
    "        font_size=12,\n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "# Create enhanced visualizations\n",
    "def create_journey_insights(timeline_df, journey_df, combined_df):\n",
    "    \"\"\"Create comprehensive journey visualizations\"\"\"\n",
    "    \n",
    "    # 1. Journey Length Distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(data=journey_df, x='length', bins=20)\n",
    "    plt.title('Distribution of Journey Lengths')\n",
    "    plt.xlabel('Number of Products')\n",
    "    plt.ylabel('Number of Customers')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Product Adoption Timeline\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.scatterplot(data=timeline_df, \n",
    "                   x='acquisition_date', \n",
    "                   y='product', \n",
    "                   alpha=0.5,\n",
    "                   hue='product')\n",
    "    plt.title('Product Adoption Timeline')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Product Correlation Heatmap\n",
    "    have_cols = [col for col in combined_df.columns if col.startswith('Have_')]\n",
    "    corr_matrix = combined_df[have_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, \n",
    "                annot=True, \n",
    "                cmap='RdYlBu',\n",
    "                center=0,\n",
    "                fmt='.2f')\n",
    "    plt.title('Product Adoption Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Journey Duration vs Products\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=journey_df,\n",
    "                   x='duration_days',\n",
    "                   y='length',\n",
    "                   alpha=0.5)\n",
    "    plt.title('Journey Duration vs Number of Products')\n",
    "    plt.xlabel('Journey Duration (days)')\n",
    "    plt.ylabel('Number of Products')\n",
    "    plt.show()\n",
    "\n",
    "# Create visualizations\n",
    "sankey_fig = plot_customer_journey_sankey(journey_df)\n",
    "sankey_fig.show()\n",
    "create_journey_insights(timeline_df, journey_df, combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Adoption Timeline\n",
    "def plot_product_adoption_timeline(df):\n",
    "    \"\"\"Plot timeline using valid dates only\"\"\"\n",
    "    timeline_data = analyze_product_sequence(df)\n",
    "    \n",
    "    # Filter out any remaining invalid dates (shouldn't be any)\n",
    "    timeline_data = timeline_data[pd.notna(timeline_data['acquisition_date'])]\n",
    "    \n",
    "    fig = px.scatter(timeline_data, \n",
    "                    x='acquisition_date', \n",
    "                    y='product',\n",
    "                    color='product',\n",
    "                    title='Product Adoption Timeline')\n",
    "    fig.update_layout(height=600)\n",
    "    fig.show()\n",
    "    \n",
    "plot_product_adoption_timeline(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34349a99-5880-446d-a287-6f6be2eb235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_starter_products(journey_df, combined_df):\n",
    "    \"\"\"Analyze the most common starter products and their subsequent journeys\"\"\"\n",
    "    \n",
    "    # Get top 3 starter products\n",
    "    top_starters = journey_df['first_product'].value_counts().head(3)\n",
    "    \n",
    "    # For each top starter, analyze the typical journey\n",
    "    starter_insights = {}\n",
    "    for product in top_starters.index:\n",
    "        # Get customers who started with this product\n",
    "        starter_journeys = journey_df[journey_df['first_product'] == product]\n",
    "        \n",
    "        # Get customer IDs for demographic analysis\n",
    "        customer_ids = starter_journeys.index\n",
    "        customer_data = combined_df[combined_df['sCustomerNaturalKey'].isin(customer_ids)]\n",
    "        \n",
    "        insights = {\n",
    "            'total_customers': len(starter_journeys),\n",
    "            'avg_journey_length': starter_journeys['length'].mean(),\n",
    "            'avg_journey_duration': starter_journeys['duration_days'].mean(),\n",
    "            'common_next_products': starter_journeys[starter_journeys['length'] > 1]['sequence'].apply(\n",
    "                lambda x: x.split(' → ')[1] if ' → ' in x else None\n",
    "            ).value_counts().head(3),\n",
    "            'customer_profile': {\n",
    "                'avg_age': customer_data['Age'].mean(),\n",
    "                'pct_women': (customer_data['Woman'] == 1).mean() * 100,\n",
    "                'pct_apartment': (customer_data['Apartment'] == 1).mean() * 100,\n",
    "                'common_lifestyle': customer_data['LifestyleGroupCode'].mode().iloc[0]\n",
    "            }\n",
    "        }\n",
    "        starter_insights[product] = insights\n",
    "    \n",
    "    return starter_insights, top_starters\n",
    "\n",
    "def visualize_starter_product_journeys(journey_df, top_starters):\n",
    "    \"\"\"Create visualizations for top starter product journeys\"\"\"\n",
    "    \n",
    "    # 1. Sankey diagram for each starter product\n",
    "    for product in top_starters.index:\n",
    "        starter_journeys = journey_df[journey_df['first_product'] == product]\n",
    "        \n",
    "        # Create Sankey for this starter product\n",
    "        fig = plot_customer_journey_sankey(starter_journeys, max_paths=5)\n",
    "        fig.update_layout(title=f\"Customer Journeys Starting with {product}\")\n",
    "        fig.show()\n",
    "    \n",
    "    # 2. Journey length comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    journey_lengths = []\n",
    "    for product in top_starters.index:\n",
    "        lengths = journey_df[journey_df['first_product'] == product]['length']\n",
    "        journey_lengths.append(lengths)\n",
    "    \n",
    "    plt.boxplot(journey_lengths, labels=top_starters.index)\n",
    "    plt.title('Journey Lengths by Starter Product')\n",
    "    plt.ylabel('Number of Products')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Time to second product\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    time_to_second = []\n",
    "    labels = []\n",
    "    for product in top_starters.index:\n",
    "        starter_journeys = journey_df[journey_df['first_product'] == product]\n",
    "        multi_product = starter_journeys[starter_journeys['length'] > 1]\n",
    "        if len(multi_product) > 0:\n",
    "            time_to_second.append(multi_product['duration_days'] / multi_product['length'])\n",
    "            labels.append(product)\n",
    "    \n",
    "    plt.boxplot(time_to_second, labels=labels)\n",
    "    plt.title('Time to Second Product by Starter Product')\n",
    "    plt.ylabel('Days')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "starter_insights, top_starters = analyze_starter_products(journey_df, combined_df)\n",
    "print(\"\\nTop Starter Product Insights:\")\n",
    "for product, insights in starter_insights.items():\n",
    "    print(f\"\\n{product}:\")\n",
    "    print(f\"Total Customers: {insights['total_customers']:,}\")\n",
    "    print(f\"Average Journey Length: {insights['avg_journey_length']:.2f} products\")\n",
    "    print(f\"Average Journey Duration: {insights['avg_journey_duration']:.1f} days\")\n",
    "    print(\"\\nCommon Next Products:\")\n",
    "    print(insights['common_next_products'])\n",
    "    print(\"\\nCustomer Profile:\")\n",
    "    for key, value in insights['customer_profile'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create visualizations\n",
    "visualize_starter_product_journeys(journey_df, top_starters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c145a0-bf6b-4cf8-a875-aee44cd3852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_customer_segments(journey_df, combined_df):\n",
    "    \"\"\"Analyze customer segments based on their journeys\"\"\"\n",
    "    \n",
    "    # Create customer segments\n",
    "    segments = pd.DataFrame()\n",
    "    segments['journey_length'] = journey_df['length']\n",
    "    segments['journey_duration'] = journey_df['duration_days']\n",
    "    segments['first_product'] = journey_df['first_product']\n",
    "    \n",
    "    # Add customer demographics\n",
    "    segments['age'] = combined_df.set_index('sCustomerNaturalKey')['Age']\n",
    "    segments['is_woman'] = combined_df.set_index('sCustomerNaturalKey')['Woman']\n",
    "    segments['lifestyle'] = combined_df.set_index('sCustomerNaturalKey')['LifestyleGroupCode']\n",
    "    \n",
    "    # Create segment labels\n",
    "    segments['segment'] = pd.qcut(segments['journey_length'], q=3, labels=['Basic', 'Moderate', 'Extensive'])\n",
    "    \n",
    "    # Analyze segments\n",
    "    segment_insights = {}\n",
    "    for segment in segments['segment'].unique():\n",
    "        segment_data = segments[segments['segment'] == segment]\n",
    "        insights = {\n",
    "            'size': len(segment_data),\n",
    "            'avg_products': segment_data['journey_length'].mean(),\n",
    "            'avg_duration': segment_data['journey_duration'].mean(),\n",
    "            'common_starter': segment_data['first_product'].mode().iloc[0],\n",
    "            'avg_age': segment_data['age'].mean(),\n",
    "            'pct_women': (segment_data['is_woman'] == 1).mean() * 100,\n",
    "            'common_lifestyle': segment_data['lifestyle'].mode().iloc[0]\n",
    "        }\n",
    "        segment_insights[segment] = insights\n",
    "    \n",
    "    return segment_insights, segments\n",
    "\n",
    "# Analyze customer segments\n",
    "segment_insights, segments = analyze_customer_segments(journey_df, combined_df)\n",
    "print(\"\\nCustomer Segment Insights:\")\n",
    "for segment, insights in segment_insights.items():\n",
    "    print(f\"\\n{segment} Segment:\")\n",
    "    for key, value in insights.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b702fc",
   "metadata": {},
   "source": [
    "## Additional Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3b0d7-84b3-4010-b2f5-735186e2aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Journey Pattern Analysis\n",
    "def analyze_journey_patterns(journey_df, combined_df):\n",
    "    \"\"\"Analyze patterns in customer journeys\"\"\"\n",
    "    patterns = {\n",
    "        'journey_stats': {\n",
    "            'total_customers': len(journey_df),\n",
    "            'avg_products': journey_df['length'].mean(),\n",
    "            'avg_duration': journey_df['duration_days'].mean(),\n",
    "            'common_first': journey_df['first_product'].value_counts().head(),\n",
    "            'common_last': journey_df['last_product'].value_counts().head()\n",
    "        },\n",
    "        'journey_segments': {\n",
    "            'single_product': (journey_df['length'] == 1).mean(),\n",
    "            'short_journey': ((journey_df['length'] > 1) & (journey_df['length'] <= 3)).mean(),\n",
    "            'long_journey': (journey_df['length'] > 3).mean()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "# Analyze patterns\n",
    "patterns = analyze_journey_patterns(journey_df, combined_df)\n",
    "print(\"\\nJourney Analysis Results:\")\n",
    "for category, stats in patterns.items():\n",
    "    print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product combinations analysis\n",
    "def analyze_product_combinations(df):\n",
    "    \"\"\"Analyze which products are commonly held together\"\"\"\n",
    "    have_cols = [col for col in df.columns if col.startswith('Have_')]\n",
    "    product_combinations = df[have_cols].sum()\n",
    "    \n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df[have_cols].corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Product Combination Correlations')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return product_combinations\n",
    "\n",
    "print(\"Product ownership analysis:\")\n",
    "display(analyze_product_combinations(combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aeb33c-23c7-43a5-9a5e-687dd02b9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demographic_insights(journey_df, combined_df):\n",
    "    \"\"\"Create detailed demographic visualizations for different journey types\"\"\"\n",
    "    \n",
    "    # 1. Age distribution by journey length\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    journey_length_bins = pd.qcut(journey_df['length'], q=3, labels=['Short', 'Medium', 'Long'])\n",
    "    combined_df['journey_length_category'] = journey_length_bins\n",
    "    \n",
    "    sns.boxplot(data=combined_df, x='journey_length_category', y='Age')\n",
    "    plt.title('Age Distribution by Journey Length')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Product preferences by gender\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    gender_prefs = pd.DataFrame()\n",
    "    have_cols = [col for col in combined_df.columns if col.startswith('Have_')]\n",
    "    \n",
    "    for col in have_cols:\n",
    "        gender_prefs[col] = combined_df.groupby('Woman')[col].mean()\n",
    "    \n",
    "    gender_prefs = gender_prefs.T\n",
    "    gender_prefs.columns = ['Men', 'Women']\n",
    "    gender_prefs.plot(kind='bar')\n",
    "    plt.title('Product Preferences by Gender')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Lifestyle group analysis\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    lifestyle_journey = combined_df.groupby('LifestyleGroupCode')['journey_length_category'].value_counts(normalize=True).unstack()\n",
    "    lifestyle_journey.plot(kind='bar', stacked=True)\n",
    "    plt.title('Journey Lengths by Lifestyle Group')\n",
    "    plt.xlabel('Lifestyle Group')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.legend(title='Journey Length')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize insights\n",
    "create_demographic_insights(journey_df, combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2c539-0042-40ba-9a00-27294d06fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_customer_segments(segments):\n",
    "    \"\"\"Create visualizations for customer segments\"\"\"\n",
    "    \n",
    "    # 1. Segment size comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    segments['segment'].value_counts().plot(kind='bar')\n",
    "    plt.title('Size of Customer Segments')\n",
    "    plt.xlabel('Segment')\n",
    "    plt.ylabel('Number of Customers')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Age distribution by segment\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=segments, x='segment', y='age')\n",
    "    plt.title('Age Distribution by Customer Segment')\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Product mix by segment\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    segments.groupby('segment')['first_product'].value_counts(normalize=True).unstack().plot(kind='bar', stacked=True)\n",
    "    plt.title('First Product Distribution by Segment')\n",
    "    plt.xlabel('Segment')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.legend(title='First Product', bbox_to_anchor=(1.05, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize insights\n",
    "visualize_customer_segments(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892b091",
   "metadata": {},
   "source": [
    "## Optional: Predictive Modeling"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c841c07-a9ab-463e-b86b-e4538351d04b",
   "metadata": {},
   "source": [
    "class CustomerJourneyPredictor(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(64, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"Prepare features for the prediction model\"\"\"\n",
    "    feature_cols = [col for col in df.columns if col.startswith(('Have_', 'Had_', 'nbr_active_agr_'))]\n",
    "    X = df[feature_cols]\n",
    "    y = df['myTarget']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return torch.FloatTensor(X_scaled), torch.FloatTensor(y.values)\n",
    "\n",
    "# Prepare data and initialize model\n",
    "X, y = prepare_features(combined_df)\n",
    "model = CustomerJourneyPredictor(X.shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
