{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9e8279",
   "metadata": {},
   "source": [
    "# Customer Journey Analysis\n",
    "# This notebook analyzes customer journeys across different products, visualizing patterns in purchasing behavior, demographics, and product adoption sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e994e0",
   "metadata": {},
   "source": [
    "## Import and plot-style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cfcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use(\"seaborn-v0_8-dark-palette\")\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abcd216",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll load all ABT_score files and combine them with appropriate target labels.\n",
    "def load_abt_files():\n",
    "    \"\"\"Load all ABT_score files and combine them with appropriate target labels\"\"\"\n",
    "    abt_files = Path('.').glob('ABT_score_*.csv') # Change this path to the location/name of your files.\n",
    "    dfs = []\n",
    "    \n",
    "    for file_path in abt_files:\n",
    "        product = file_path.stem.split('_')[-1]\n",
    "        print(f\"Loading {product} data...\")\n",
    "        df = pd.read_csv(file_path, sep=';')\n",
    "        df['product_type'] = product\n",
    "        dfs.append(df)\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Load the data\n",
    "combined_df = load_abt_files()\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"Total number of records: {len(combined_df)}\")\n",
    "print(\"\\nProduct distribution:\")\n",
    "print(combined_df['product_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a55e99",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data and prepare it for analysis.\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Clean and preprocess the combined dataset\"\"\"\n",
    "    # Convert date columns to datetime\n",
    "    date_columns = [col for col in df.columns if 'Date' in col or 'date' in col]\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    # Convert binary columns to int\n",
    "    binary_columns = [col for col in df.columns if col.startswith('Have_') or \n",
    "                     col.startswith('Had_') or \n",
    "                     col.startswith('Optout_')]\n",
    "    for col in binary_columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "combined_df = preprocess_data(combined_df)\n",
    "\n",
    "# Display sample of preprocessed data\n",
    "print(\"Sample of preprocessed data:\")\n",
    "display(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08cec7a",
   "metadata": {},
   "source": [
    "## Customer Journey Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the sequence of products purchased by customers.\n",
    "def analyze_product_sequence(df):\n",
    "    \"\"\"Analyze the sequence of products purchased by customers\"\"\"\n",
    "    product_cols = [col for col in df.columns if col.startswith('mFirst_')]\n",
    "    \n",
    "    # Create a timeline of product acquisitions\n",
    "    product_timeline = pd.DataFrame()\n",
    "    for col in product_cols:\n",
    "        product = col.replace('mFirst_', '')\n",
    "        mask = ~df[col].isna()\n",
    "        if mask.any():\n",
    "            product_timeline = pd.concat([\n",
    "                product_timeline,\n",
    "                pd.DataFrame({\n",
    "                    'sCustomerNaturalKey': df.loc[mask, 'sCustomerNaturalKey'],\n",
    "                    'product': product,\n",
    "                    'acquisition_date': df.loc[mask, col]\n",
    "                })\n",
    "            ])\n",
    "    \n",
    "    return product_timeline.sort_values('acquisition_date')\n",
    "\n",
    "# Analyze product sequences\n",
    "product_timeline = analyze_product_sequence(combined_df)\n",
    "\n",
    "# Display summary of product sequences\n",
    "print(\"Most common first products:\")\n",
    "display(product_timeline.groupby('sCustomerNaturalKey')\n",
    "        .first()['product']\n",
    "        .value_counts()\n",
    "        .head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e9309",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Journey Sankey Diagram\n",
    "def plot_customer_journey_sankey(df):\n",
    "    \"\"\"Create a Sankey diagram of customer journeys\"\"\"\n",
    "    product_sequence = analyze_product_sequence(df)\n",
    "    \n",
    "    # Group by customer and create product sequences\n",
    "    customer_sequences = product_sequence.groupby('sCustomerNaturalKey').agg(\n",
    "        list\n",
    "    )['product'].value_counts().head(10)  # Top 10 most common sequences\n",
    "    \n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node = dict(\n",
    "            pad = 15,\n",
    "            thickness = 20,\n",
    "            line = dict(color = \"black\", width = 0.5),\n",
    "            label = customer_sequences.index,\n",
    "            color = \"blue\"\n",
    "        ),\n",
    "        link = dict(\n",
    "            source = [i for i in range(len(customer_sequences)-1)],\n",
    "            target = [i+1 for i in range(len(customer_sequences)-1)],\n",
    "            value = customer_sequences.values[:-1]\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(title_text=\"Most Common Customer Journey Paths\", \n",
    "                     font_size=10,\n",
    "                     height=600)\n",
    "    fig.show()\n",
    "\n",
    "# Create Sankey diagram\n",
    "plot_customer_journey_sankey(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a782b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic Analysis\n",
    "def plot_demographic_distribution(df):\n",
    "    \"\"\"Plot age and gender distribution for different products\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Age distribution\n",
    "    sns.boxplot(x='product_type', y='Age', data=df, ax=ax1)\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)\n",
    "    ax1.set_title('Age Distribution by Product')\n",
    "    \n",
    "    # Gender distribution\n",
    "    gender_dist = df.groupby(['product_type', 'Woman']).size().unstack()\n",
    "    gender_dist.plot(kind='bar', stacked=True, ax=ax2)\n",
    "    ax2.set_title('Gender Distribution by Product')\n",
    "    ax2.legend(['Male', 'Female'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional demographic insights\n",
    "    print(\"\\nMean age by product:\")\n",
    "    display(df.groupby('product_type')['Age'].mean().sort_values(ascending=False))\n",
    "\n",
    "plot_demographic_distribution(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Adoption Timeline\n",
    "def plot_product_adoption_timeline(df):\n",
    "    \"\"\"Plot timeline of product adoption\"\"\"\n",
    "    timeline_data = analyze_product_sequence(df)\n",
    "    \n",
    "    fig = px.scatter(timeline_data, \n",
    "                    x='acquisition_date', \n",
    "                    y='product',\n",
    "                    color='product',\n",
    "                    title='Product Adoption Timeline')\n",
    "    \n",
    "    fig.update_layout(height=600)\n",
    "    fig.show()\n",
    "    \n",
    "    # Additional timeline insights\n",
    "    print(\"\\nMedian time between first and second product (days):\")\n",
    "    customer_products = timeline_data.groupby('sCustomerNaturalKey')\n",
    "    time_between = customer_products.acquisition_date.agg(lambda x: x.diff().median().days)\n",
    "    display(time_between.median())\n",
    "\n",
    "plot_product_adoption_timeline(combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892b091",
   "metadata": {},
   "source": [
    "## Optional: Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use PyTorch to build a model predicting future product adoption.\n",
    "class CustomerJourneyPredictor(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(64, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"Prepare features for the prediction model\"\"\"\n",
    "    feature_cols = [col for col in df.columns if col.startswith(('Have_', 'Had_', 'nbr_active_agr_'))]\n",
    "    X = df[feature_cols]\n",
    "    y = df['myTarget']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return torch.FloatTensor(X_scaled), torch.FloatTensor(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data and initialize model\n",
    "X, y = prepare_features(combined_df)\n",
    "model = CustomerJourneyPredictor(X.shape[1])\n",
    "print(\"Model architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b702fc",
   "metadata": {},
   "source": [
    "## Additional Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product combinations analysis\n",
    "def analyze_product_combinations(df):\n",
    "    \"\"\"Analyze which products are commonly held together\"\"\"\n",
    "    have_cols = [col for col in df.columns if col.startswith('Have_')]\n",
    "    product_combinations = df[have_cols].sum()\n",
    "    \n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df[have_cols].corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Product Combination Correlations')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return product_combinations\n",
    "\n",
    "print(\"Product ownership analysis:\")\n",
    "display(analyze_product_combinations(combined_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
