{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9e8279",
   "metadata": {},
   "source": [
    "# Customer Journey Analysis\n",
    "# This notebook analyzes customer journeys across different products, visualizing patterns in purchasing behavior, demographics, and product adoption sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e994e0",
   "metadata": {},
   "source": [
    "## Import and plot-style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16cfcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use(\"seaborn-v0_8-dark-palette\")\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abcd216",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c26053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 ABT_score files:\n",
      "  - ABT_Score_Example.csv\n",
      "\n",
      "Loading Example data...\n",
      "Successfully loaded 0 rows for Example\n",
      "\n",
      "Dataset Overview:\n",
      "Total number of records: 0\n",
      "\n",
      "Product distribution:\n",
      "Series([], Name: product_type, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# We'll load all ABT_score files and combine them with appropriate target labels.\n",
    "def load_abt_files():\n",
    "    \"\"\"Load all ABT_score files and combine them with appropriate target labels\"\"\"\n",
    "    # List all ABT_Score/ABT_score files in current directory (case insensitive)\n",
    "    abt_files = list(Path('../data').glob('ABT_[Ss]core_*.csv'))\n",
    "    \n",
    "    # Check if any files were found\n",
    "    if not abt_files:\n",
    "        print(\"No ABT_score_*.csv files found in current directory!\")\n",
    "        print(\"\\nCurrent directory contents:\")\n",
    "        print([f.name for f in Path('../data').glob('*')])\n",
    "        print(\"\\nPlease ensure your ABT_score_*.csv files are in the data directory.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(abt_files)} ABT_score files:\")\n",
    "    for f in abt_files:\n",
    "        print(f\"  - {f.name}\")\n",
    "    \n",
    "    dfs = []\n",
    "    for file_path in abt_files:\n",
    "        product = file_path.stem.split('_')[-1]\n",
    "        try:\n",
    "            print(f\"\\nLoading {product} data...\")\n",
    "            df = pd.read_csv(file_path, sep=';')\n",
    "            print(f\"Successfully loaded {len(df)} rows for {product}\")\n",
    "            df['product_type'] = product\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path.name}: {str(e)}\")\n",
    "    \n",
    "    if not dfs:\n",
    "        raise ValueError(\"No data frames were successfully loaded. Please check the file format and contents.\")\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Load the data\n",
    "combined_df = load_abt_files()\n",
    "\n",
    "if combined_df is not None:\n",
    "    # Display basic information about the dataset\n",
    "    print(\"\\nDataset Overview:\")\n",
    "    print(f\"Total number of records: {len(combined_df)}\")\n",
    "    print(\"\\nProduct distribution:\")\n",
    "    print(combined_df['product_type'].value_counts())\n",
    "else:\n",
    "    print(\"\\nPlease fix the data loading issues before continuing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a55e99",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dab03d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of preprocessed data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>myTarget</th>\n",
       "      <th>sCustomerNaturalKey</th>\n",
       "      <th>myTarget_boughtDate</th>\n",
       "      <th>mLastStart_Bank</th>\n",
       "      <th>mLastStart_Pension</th>\n",
       "      <th>mFirst_Personbil</th>\n",
       "      <th>nbr_active_agr_Bank</th>\n",
       "      <th>Have_Bank</th>\n",
       "      <th>Age</th>\n",
       "      <th>OpenRate</th>\n",
       "      <th>Email_contacted</th>\n",
       "      <th>Apartment</th>\n",
       "      <th>Woman</th>\n",
       "      <th>Mobile_exist</th>\n",
       "      <th>Email_exist</th>\n",
       "      <th>product_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [myTarget, sCustomerNaturalKey, myTarget_boughtDate, mLastStart_Bank, mLastStart_Pension, mFirst_Personbil, nbr_active_agr_Bank, Have_Bank, Age, OpenRate, Email_contacted, Apartment, Woman, Mobile_exist, Email_exist , product_type]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean the data and prepare it for analysis.\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Clean and preprocess the combined dataset\"\"\"\n",
    "    # Convert date columns to datetime\n",
    "    date_columns = [col for col in df.columns if 'Date' in col or 'date' in col]\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    # Convert binary columns to int\n",
    "    binary_columns = [col for col in df.columns if col.startswith('Have_') or \n",
    "                     col.startswith('Had_') or \n",
    "                     col.startswith('Optout_')]\n",
    "    for col in binary_columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "combined_df = preprocess_data(combined_df)\n",
    "\n",
    "# Display sample of preprocessed data\n",
    "print(\"Sample of preprocessed data:\")\n",
    "display(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08cec7a",
   "metadata": {},
   "source": [
    "## Customer Journey Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "569b99bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acquisition_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kt/sr5ybsdd4fdd57yn3llfr_kr0000gn/T/ipykernel_16219/1209664667.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproduct_timeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acquisition_date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Analyze product sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mproduct_timeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_product_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Display summary of product sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Most common first products:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kt/sr5ybsdd4fdd57yn3llfr_kr0000gn/T/ipykernel_16219/1209664667.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;34m'acquisition_date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mproduct_timeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acquisition_date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_format_argument_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6909\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6911\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6912\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6914\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6915\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acquisition_date'"
     ]
    }
   ],
   "source": [
    "# Analyze the sequence of products purchased by customers.\n",
    "def analyze_product_sequence(df):\n",
    "    \"\"\"Analyze the sequence of products purchased by customers\"\"\"\n",
    "    product_cols = [col for col in df.columns if col.startswith('mFirst_')]\n",
    "    \n",
    "    # Create a timeline of product acquisitions\n",
    "    product_timeline = pd.DataFrame()\n",
    "    for col in product_cols:\n",
    "        product = col.replace('mFirst_', '')\n",
    "        mask = ~df[col].isna()\n",
    "        if mask.any():\n",
    "            product_timeline = pd.concat([\n",
    "                product_timeline,\n",
    "                pd.DataFrame({\n",
    "                    'sCustomerNaturalKey': df.loc[mask, 'sCustomerNaturalKey'],\n",
    "                    'product': product,\n",
    "                    'acquisition_date': df.loc[mask, col]\n",
    "                })\n",
    "            ])\n",
    "    \n",
    "    return product_timeline.sort_values('acquisition_date')\n",
    "\n",
    "# Analyze product sequences\n",
    "product_timeline = analyze_product_sequence(combined_df)\n",
    "\n",
    "# Display summary of product sequences\n",
    "print(\"Most common first products:\")\n",
    "display(product_timeline.groupby('sCustomerNaturalKey')\n",
    "        .first()['product']\n",
    "        .value_counts()\n",
    "        .head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7e9309",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Journey Sankey Diagram\n",
    "def plot_customer_journey_sankey(df):\n",
    "    \"\"\"Create a Sankey diagram of customer journeys\"\"\"\n",
    "    product_sequence = analyze_product_sequence(df)\n",
    "    \n",
    "    # Group by customer and create product sequences\n",
    "    customer_sequences = product_sequence.groupby('sCustomerNaturalKey').agg(\n",
    "        list\n",
    "    )['product'].value_counts().head(10)  # Top 10 most common sequences\n",
    "    \n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node = dict(\n",
    "            pad = 15,\n",
    "            thickness = 20,\n",
    "            line = dict(color = \"black\", width = 0.5),\n",
    "            label = customer_sequences.index,\n",
    "            color = \"blue\"\n",
    "        ),\n",
    "        link = dict(\n",
    "            source = [i for i in range(len(customer_sequences)-1)],\n",
    "            target = [i+1 for i in range(len(customer_sequences)-1)],\n",
    "            value = customer_sequences.values[:-1]\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig.update_layout(title_text=\"Most Common Customer Journey Paths\", \n",
    "                     font_size=10,\n",
    "                     height=600)\n",
    "    fig.show()\n",
    "\n",
    "# Create Sankey diagram\n",
    "plot_customer_journey_sankey(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a782b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic Analysis\n",
    "def plot_demographic_distribution(df):\n",
    "    \"\"\"Plot age and gender distribution for different products\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Age distribution\n",
    "    sns.boxplot(x='product_type', y='Age', data=df, ax=ax1)\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)\n",
    "    ax1.set_title('Age Distribution by Product')\n",
    "    \n",
    "    # Gender distribution\n",
    "    gender_dist = df.groupby(['product_type', 'Woman']).size().unstack()\n",
    "    gender_dist.plot(kind='bar', stacked=True, ax=ax2)\n",
    "    ax2.set_title('Gender Distribution by Product')\n",
    "    ax2.legend(['Male', 'Female'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional demographic insights\n",
    "    print(\"\\nMean age by product:\")\n",
    "    display(df.groupby('product_type')['Age'].mean().sort_values(ascending=False))\n",
    "\n",
    "plot_demographic_distribution(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Adoption Timeline\n",
    "def plot_product_adoption_timeline(df):\n",
    "    \"\"\"Plot timeline of product adoption\"\"\"\n",
    "    timeline_data = analyze_product_sequence(df)\n",
    "    \n",
    "    fig = px.scatter(timeline_data, \n",
    "                    x='acquisition_date', \n",
    "                    y='product',\n",
    "                    color='product',\n",
    "                    title='Product Adoption Timeline')\n",
    "    \n",
    "    fig.update_layout(height=600)\n",
    "    fig.show()\n",
    "    \n",
    "    # Additional timeline insights\n",
    "    print(\"\\nMedian time between first and second product (days):\")\n",
    "    customer_products = timeline_data.groupby('sCustomerNaturalKey')\n",
    "    time_between = customer_products.acquisition_date.agg(lambda x: x.diff().median().days)\n",
    "    display(time_between.median())\n",
    "\n",
    "plot_product_adoption_timeline(combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892b091",
   "metadata": {},
   "source": [
    "## Optional: Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use PyTorch to build a model predicting future product adoption.\n",
    "class CustomerJourneyPredictor(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(64, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def prepare_features(df):\n",
    "    \"\"\"Prepare features for the prediction model\"\"\"\n",
    "    feature_cols = [col for col in df.columns if col.startswith(('Have_', 'Had_', 'nbr_active_agr_'))]\n",
    "    X = df[feature_cols]\n",
    "    y = df['myTarget']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return torch.FloatTensor(X_scaled), torch.FloatTensor(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data and initialize model\n",
    "X, y = prepare_features(combined_df)\n",
    "model = CustomerJourneyPredictor(X.shape[1])\n",
    "print(\"Model architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b702fc",
   "metadata": {},
   "source": [
    "## Additional Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bc443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product combinations analysis\n",
    "def analyze_product_combinations(df):\n",
    "    \"\"\"Analyze which products are commonly held together\"\"\"\n",
    "    have_cols = [col for col in df.columns if col.startswith('Have_')]\n",
    "    product_combinations = df[have_cols].sum()\n",
    "    \n",
    "    # Create correlation matrix\n",
    "    corr_matrix = df[have_cols].corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Product Combination Correlations')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return product_combinations\n",
    "\n",
    "print(\"Product ownership analysis:\")\n",
    "display(analyze_product_combinations(combined_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
